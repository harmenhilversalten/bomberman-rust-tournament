## 4. High-Level Architecture Overview

### 4.1 System Components and Data Flow

The high-level architecture of the Bomberman AI agent is designed as a hierarchical, data-flow oriented system, facilitating parallelism and clear separation of concerns. At the top sits the Game Engine (in the`engine` crate), responsible for running the core game physics and simulation. The engine communicates with a central Shared State component (in the`state` crate), which holds the authoritative state of the game world (`Arc<RwLock<GameGrid>>`). This shared state is updated every tick by the engine, which also emits State Deltas (dashed lines in the diagram) representing changes from the previous tick. These deltas are crucial for efficient incremental updates in downstream components. The Shared State provides read-only, lock-free Grid Snapshots to individual Per-Bot Decision Tasks. Each bot operates in its own asynchronous task or thread, allowing for concurrent decision-making.

Within each Per-Bot Decision Task, the Bot Kernel orchestrates the agent's logic. The kernel first consults the Goal Manager to determine high-level objectives based on the current snapshot. The State Evaluator then scores these goals, considering factors like distance, safety, and potential rewards. Once a goal is selected, the Pathfinder generates a sequence of micro-moves to reach the target, and the Bomb Planner handles bomb-related tactics. Optionally, components like the Goal Manager or Pathfinder can be overridden by an RL Policy NN (Neural Network), allowing learned behaviors to guide these processes. Actions chosen by the kernel are submitted back to the Game Engine (via the Shared State or a direct channel) for execution. An RL Reward Buffer within the bot kernel can accumulate rewards during an RL episode. This structured flow ensures that each component has a well-defined responsibility and interacts with others through clear data interfaces, promoting both performance and maintainability.

### 4.2 Concurrency and Parallelism Model

The concurrency model is designed to maximize performance by leveraging Rust's robust support for asynchronous and parallel execution. The Main Engine Thread (in the`engine` crate) is responsible for managing the GameGrid, simulating game ticks, and emitting state deltas. To handle potentially hundreds of AI agents, each Bot operates within its own Per-Bot Decision Task. These tasks can be implemented as asynchronous tasks (e.g., using Tokio's runtime) or as standard library threads, scaling with the available CPU cores, potentially managed by a thread pool like Rayon. Communication between the main engine thread and the bot tasks, as well as between different components within a bot task, utilizes Rust's channel primitives. Specifically, watch channels are suitable for broadcasting state deltas from the GameGrid to all subscribed bot tasks, ensuring they receive timely updates. For bot commands (actions to be executed in the game world), mpsc (multi-producer, single-consumer) channels can be used to send requests from bot tasks back to the game engine.

To ensure data integrity and avoid locks on the hot path of decision-making, the architecture employs lock-free programming techniques, primarily through the use of crossbeam-epoch for managing GridSnapshot access. This allows multiple bot tasks to concurrently read the game state without blocking each other or the main engine thread. For computationally intensive operations within AI components, such as updating large influence maps or performing complex pathfinding, further parallelism can be introduced using Rayon's parallel iterators or by spawning additional short-lived tasks. For instance, influence map updates for multiple independent blast waves could be parallelized. The architecture also suggests considering an Entity-Component System (ECS) framework like specs if the number of agents and game entities grows very large (e.g., 100+), as ECS can offer a more data-oriented and cache-efficient approach to managing game state and AI logic. For Reinforcement Learning, batched inference for multiple agents can be performed in parallel using Rayon, and model loading can be handled asynchronously to avoid blocking the decision loop.

---

