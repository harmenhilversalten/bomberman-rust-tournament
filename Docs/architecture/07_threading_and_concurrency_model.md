## 7. Threading & Concurrency Model

### 7.1 Engine and Bot Task Management

The threading and concurrency model is designed to maximize parallelism and ensure responsive AI decision-making. The Main Engine Thread is responsible for the core game loop: updating the GameGrid, simulating physics, handling player inputs (if any), and emitting GridDelta events that represent changes in the game state. This thread operates at a fixed tick rate (e.g., 60 Hz). To handle AI for multiple agents, each Bot is assigned its own Per-Bot Decision Task. These tasks can be implemented as asynchronous tasks, managed by a runtime like Tokio, or as standard library threads. If using threads, a thread pool, possibly managed by Rayon, can be used to limit the number of concurrent threads to the number of available CPU cores, preventing resource exhaustion. These bot tasks run concurrently, allowing multiple agents to process their logic and make decisions simultaneously. This parallel processing is crucial for achieving the target throughput of 1 ms per bot per tick, especially when dealing with hundreds of agents. The architecture also supports batched inference for RL agents, where multiple agents' observations can be processed by a neural network in a single batch, further leveraging parallelism, potentially on a GPU if available.

(Note: References to "GameGrid" updated to "GameState from state crate"; engine thread lives in engine crate.)

### 7.2 Communication Mechanisms

Communication between the main engine thread, the shared GameGrid, and the individual bot tasks is facilitated by Rust's channel primitives, which are designed for safe and efficient inter-thread messaging. The GameGrid uses watch channels to broadcast GridDelta events to all subscribed bot tasks. A watch channel is suitable for this purpose because it maintains a single value (the latest delta) that multiple receivers can observe, and it efficiently notifies subscribers of changes. For bot commands (actions to be executed in the game world), mpsc (multi-producer, single-consumer) channels are used to send requests from bot tasks back to the engine thread. This setup ensures that commands from multiple bots can be queued and processed by the single engine thread without contention. Other communication, such as between internal AI components within a bot task, can use simpler synchronous channels or direct method calls if no concurrency is needed. Asynchronous channels (from tokio) are preferred when the Tokio runtime is used, depending on the complexity and asynchronicity required. The choice of channels ensures that data is passed between threads safely, avoiding shared mutable state issues common in concurrent programming.

### 7.3 Lock-Free Strategies and ECS Consideration

To minimize contention and ensure low-latency decision-making, the architecture employs lock-free strategies for accessing shared game state. The most prominent example is the use of crossbeam-epoch for managing GridSnapshot access. When a bot task requests a snapshot of the GameGrid, it receives an immutable, lock-free view of the grid at a specific version. This allows multiple bots to read the game state concurrently without blocking each other or the main engine thread that might be updating the GameGrid. The epoch-based reclamation mechanism ensures that these snapshots are kept alive as long as any bot task is using them and are safely deallocated when no longer needed. This approach is critical for meeting the stringent throughput and latency requirements. For managing a very large number of entities (agents, bombs, etc.), the architecture suggests considering an Entity-Component-System (ECS) framework like specs. ECS provides a data-oriented design pattern that can improve cache locality and parallelism for systems that process many entities. While not explicitly implemented in the current module structure, it's a viable path for future scalability if the complexity of game entities and their interactions grows significantly beyond the initial targets. The RL components, such as model loading, can also benefit from asynchronous operations to avoid blocking the main decision loops of the bots.

---

